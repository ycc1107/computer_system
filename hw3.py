import re
import json
import csv
import numpy as np
import pandas as pd
import usaddress
from fuzzywuzzy import fuzz
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV


def load_file(file_name):
  if file_name.endswith('csv'):
    return pd.read_csv(file_name)
  elif file_name.endswith('json'):
    return pd.read_json(file_name)

def street_func(item):
  item_lst = usaddress.parse(item)
  item_dict = {i[1]:i[0] for i in item_lst}
  return item_dict.get('AddressNumber', ''), item_dict.get('StreetName', ''), item_dict.get('StreetNamePostType', ''), item_dict.get('OccupancyIdentifier', '')

def feature_engine(agg_df):
    agg_df['address_number'], agg_df['street_name'], agg_df['street_name_post'], agg_df['occupancy_id'] = zip(*agg_df.street_address.apply(street_func))
    agg_df = agg_df.assign(longitude=agg_df.longitude.apply(lambda x: x or '-1'))
    agg_df = agg_df.assign(latitude=agg_df.latitude.apply(lambda x: x or '-1'))
    agg_df = agg_df.assign(postal_code=agg_df.postal_code.apply(lambda x: x or '-1'))
    
    return agg_df

def fuzzy_ratio(cols, row1, row2):
    res = []
    for name in cols:
        if isinstance(row1[name], float) or isinstance(row2[name], float):
            calc_tmp = abs(float(row1[name]) / float(row2[name]) - 1)
            precision = 0
            for i in str(calc_tmp).split('.')[-1]:
                if i == '0':
                    precision += 1
                if i != '0':
                    break
            
            num = 100 - int(calc_tmp * 10**(precision + 2))
            res.append(num)
        else:
            res.append(fuzz.ratio(row1[name], row2[name]))
    return res

def gen_feature_matrix(four_df, loc_df):
    cols = ['street_name_post', 'occupancy_id', 'phone', 'address_number', 'street_name', 'name', 'region', 'locality']
    res = []            
    for _, row in four_df.iterrows():
        for _, row2 in loc_df.iterrows():
            tmp = [row.id]
            tmp.append(row2.id)
            tmp.extend(fuzzy_ratio(cols, row, row2))
            res.append(tmp)
    return pd.DataFrame(res,columns = ['four_id','loc_id'] + cols)

def process_data(four_path, locu_path, train_path=None):
    locu_df = load_file(locu_path)
    locu_df = locu_df.fillna('')
    four_df = load_file(four_path)
    four_df = four_df.fillna('')
    if train_path:
        label = load_file(train_path)
    four_df = four_df.assign(phone=four_df.phone.apply(lambda x: x.replace('(', '').replace(')', '').replace('-', '').replace(' ', '')))
    
    new_four_df = feature_engine(four_df)
    new_locu_df = feature_engine(locu_df)

    feature_matrix = gen_feature_matrix(new_four_df, new_locu_df)

    if train_path:
        matching_label = set()
        for _, row in label.iterrows():
            loc = row.locu_id
            four = row.foursquare_id
            matching_label.add(four+loc)
            
        feature_matrix = feature_matrix.assign(matching = feature_matrix.apply(lambda row: int((row['four_id'] + row['loc_id']) in matching_label), axis=1))
    
    return feature_matrix

def model(feature, label):
    MODELS = {
          "Decision Tree":DecisionTreeClassifier(max_depth=5),
          "Random Forest":RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),
          "Neural Net":MLPClassifier(alpha=0.0001),
          }
    
    MODELS_PARA = {
          "Neural Net":{'alpha':np.arange(0.0005, 0.001, 0.0001), 'hidden_layer_sizes':[(i,j) for i,j  in zip(range(5,10), range(3,8))]},
          "Decision Tree":{'max_depth':range(5,7)},
          "Random Forest":{"max_depth": range(5,7),
                          "max_features": [2, 5, 8],
                          "min_samples_split": [10, 20, 30],
                          "min_samples_leaf": [1, 3, 10, 20],
                          "bootstrap": [True, False],
                          "criterion": ["gini", "entropy"]},
         }
    
    x_train, x_test, y_train, y_test = train_test_split(feature, label, test_size=.4, random_state=42)
    max_score = 0
    for name, clf in MODELS.iteritems():
        para = MODELS_PARA.get(name, None)
        print '- begin train {} with {}'.format(name, para)

        clf = GridSearchCV(clf, para)
        clf.fit(x_train, y_train)
        score = clf.score(x_test, y_test)

        if score > max_score:
          print '- {} with {} score too low to contine'.format(name, para)
          max_score = score
          max_score_name = name
          res = clf
          print '- Max scores is {} generated by {}'.format(max_score, max_score_name)

    return res.fit(feature, label)

def get_matches(locu_train_path, foursquare_train_path, matches_train_path, locu_test_path, foursquare_test_path):
    feature_matrix = process_data(foursquare_train_path, locu_train_path, matches_train_path)
    nn_model = model(feature_matrix.drop(['four_id','loc_id', 'matching'], axis=1), feature_matrix.matching)

    test_feature_matrix = process_data(foursquare_test_path, locu_test_path)
    pre = nn_model.predict(test_feature_matrix.drop(['four_id','loc_id'], axis=1))
    test_feature_matrix['matching'] = pre

    res_df = test_feature_matrix[test_feature_matrix.matching == 1][['four_id', 'loc_id']]
    res_df.columns = ['locu_id', 'foursquare_id']
    res_df.to_csv('matches_test.csv', index=False)

if __name__ == '__main__':
    get_matches('locu_train.json', 'foursquare_train.json', 'matches_train.csv', 'locu_test.json', 'foursquare_test.json')
    

'''
street_name_post 0.0
occupancy_id 0.0
phone 0.110865315948
address_number 0.00297482798615
street_name 0.0106475609001
name 0.71099887663
region 0.0
locality 0.0
latitude 0.155794120358
longitude 0.00871929817667
'''
